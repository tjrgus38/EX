{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "concerned-electron",
   "metadata": {},
   "source": [
    "# 디렉토리 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-junior",
   "metadata": {},
   "source": [
    "mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클라우드에 가위,바위,보 라는 하위 폴더를 -p를 사용하여 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-thanksgiving",
   "metadata": {},
   "source": [
    "unzip rock.zip\n",
    "unzip scissor.zip\n",
    "unzip paper.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 하위 폴더에 사진이 들어가 있는 알집 파일을 업로드 후 압축풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indonesian-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-elimination",
   "metadata": {},
   "source": [
    "# 사진 사이즈 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "superb-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2320  images to be resized.\n",
      "2320  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visible-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2202  images to be resized.\n",
      "2202  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "united-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270  images to be resized.\n",
      "2270  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-maximum",
   "metadata": {},
   "source": [
    "# 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "military-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6792 입니다.\n",
      "x_train shape: (6792, 28, 28, 3)\n",
      "y_train shape: (6792,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=6792):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "objective-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가위, 바위, 보는 3개의 클래스로 이루어져 있고 순서대로 0,1,2\n",
    "# 세가지의 이미지 총 합을 입력 (6792장, 28x28 사이즈의 컬러 3의 값)\n",
    "# 정규화 MAX-MIN = 255이기 때문에 255.0을 나눠서 0~1의 값을 갖게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-witness",
   "metadata": {},
   "source": [
    "# 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "returning-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[50])\n",
    "print('라벨: ', y_train[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-charter",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surgical-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=8\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-milton",
   "metadata": {},
   "source": [
    "# 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confident-continent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "213/213 [==============================] - 6s 11ms/step - loss: 4.0068 - accuracy: 0.4530\n",
      "Epoch 2/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.7703\n",
      "Epoch 3/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8709\n",
      "Epoch 4/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9151\n",
      "Epoch 5/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9608\n",
      "Epoch 6/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "213/213 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c8c8092d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disciplinary-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complie을 통해 모델을 준비\n",
    "# fit을 통해 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-lesson",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-integration",
   "metadata": {},
   "source": [
    "mkdir -p ~/aiffel/rock_scissor_paper/test\n",
    "#test폴더 생성 -> 3개의 하위 폴더 생성 -> 각각의 폴더에  테스트 파일 업로드 -> 알집 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "guilty-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test1, y_test1)=load_data(image_dir_path, 300)\n",
    "x_test1_norm = x_test1/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_test1.shape))\n",
    "print(\"y_train shape: {}\".format(y_test1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "featured-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300장의 테스트 이미지 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-curve",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handy-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 3s 238ms/step - loss: 0.2387 - accuracy: 0.8987\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9851\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1cab9fc7d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_test1, y_test1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boolean-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile로 모델 준비\n",
    "# fit을 통해 학습 epochs -> 5번"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-battle",
   "metadata": {},
   "source": [
    "# 고찰\n",
    "\n",
    "지금은 깊게 하나하나 이해를 할 수는 없었지만, 간단한 이미지 딥러닝의 프로세스 흐름을 알게 되었다.\n",
    "학습할 수 있는 이미지와 테스트를 해야하는 파일을 정확히 구분하고 나눌 수 있어야하며, 조금씩 값을 변경하면서 수치가 변하는 것을 확인할 때마다 작지만 성취감을 느낄 수 있게 해주었다.\n",
    "\n",
    "loss값은 왜 저렇게 나오고, 정확도는 왜 저렇게 높게 나오는지에 대한 의문은 아직 풀고 있고, 좀 더 연구를 해봐야할 것 같다.\n",
    "가장 흥미로웠던 부분은 Maxpooling과 channel, Dense, Epoch 와 같은 가장 중요했던 부분이다.\n",
    "이미지를 특징적으로 내적하여 새로 만들어내고, 몇 개의 특징을 잡아낼 것이며, 일정 시도 이상에서 역치가 발생하는 등의 문제들은 계속해서 공부를 해보고 정리가 필요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
